%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages

\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps
\usepackage{url}
\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text


\title{STATS 116: Theory of Probability}
%A First Course in Probability, Ross.
\author{sogapalag}

\date{\normalsize\today}

\begin{document}

\maketitle

\section{Combinatorial Analysis}
The generalized basic principle of counting.\\
permutations\\
The binomial theorem\\
$n$ distinct items to $r$ distinct groups with size $\sum n_r = n$:
\begin{equation}
	{n \choose {n_1,...,n_r}} = \frac{n!}{n_1!\dots n_r!}
\end{equation}
The multinomial theorem\\
$\sum_r x_j = n, x_j>0$, number of solution (distinct integer-valued) vectors $v=(x_j,..)$, is ${n-1 \choose r-1}$.\\
if $x_j\geq 0$, number is ${n+r-1 \choose r-1}$.\\
n choose k with repetition, number is ${n+k-1 \choose n-1}$.\\
distinct $n$ items distribute to $k$ distinct groups, $(1+1+\dots+1)^n=k^n$, i.e. every items's group choice always $k$, the formula tells, there is ${n+k-1 \choose k-1}$ terms, each term corresponding to a ${n \choose {n_1,...,n_k}}$.\\
\begin{align}
	{n\choose k } &= \frac{n}{k} {n-1\choose k-1}\\
	&= {n-1 \choose k-1} + {n-1 \choose k} \\
	&= {n+1 \choose k+1} - {n\choose k+1}
\end{align}

\section{Axioms of Probability}
Distributive laws, $(E\cup F) G = EG\cup FG$, $EF\cup G = (E\cup G)(F\cup G)$\\
%样本空间的并（交）操作 对偶于 对偶空间的交（并）操作；即当作一个操作时，同时对偶空间也在操作。
DeMorgan's laws:
\begin{align}
	\left( \bigcup E_i \right)^c &= \bigcap E_i^c \\
	\left( \bigcap E_i \right)^c &= \bigcup E_i^c
\end{align}
Axiom 1, $0\leq P(E) \leq 1$;\\
Axiom 2, $P(S)=1$;\\
Axiom 3, $\forall E_iE_j = \emptyset,i\neq j$, $P(\bigcup_{i=1}^\infty E_i) = \sum_{i=1}^\infty P(E_i)$.\\
Axiom 3 implies $P(\emptyset) =0$.\\
Propositions:
\begin{align}
P(\bigcup E_i) = \sum_{r=1}^n (-1)^{r+1} \sum_{i_1<\dots<i_r} P(E_{i_1}\dots E_{i_r}) 
\end{align}
if sequence $E_n$ monotic, then $\lim P(E_n) = P(\lim E_n)$.\\

\section{Conditional Probability and Independence}
Def, $P(E|F) = \frac{P(EF)}{P(F)}$.\\
The multiplication rule,
\begin{align}
	P(E_1E_2\dots E_n) = P(E_1)P(E_2|E_1)P(E_3|E_1E_2)\dots P(E_n|E_1\dots E_{n-1})
\end{align}
def, odds $P(A)/P(A^c)$.\\
independent, $P(EF)=P(E)P(F)$.\\
prop, if E and F independent, so E and $F^c$.\\
mutually exclusive $F_i$, and $\sum P(F_i)=1$, then
\begin{align}
P(F_j|E) = \frac{P(E|F_j)P(F_j)} {\sum_i P(E|F_i)P(F_i)}
\end{align}
Laplace's rule of succession.\\

\section{Random Variables}
distribution function $F(x) = P\{X\leq x\}$.\\
countable number of possible value, discrete, $\sum_i p(x_i) = 1$.\\
If discrete, $F$ is step function.\\
expected value,(mean, first moment) $E[X] = \sum_{x:p(x)>0} xp(x)$. analogous to center of gravity\\
prop, $X$ is discrete random varible respect to $p$, for any real-valued $g$, $E[g(X)]= \sum_i g(x_i)p(x_i)$.\\
corollary, $E[aX+b] =aE[X]+b$.\\
variance $\text{Var}(X)=E[(X-\mu)^2] = E[X^2] - \mu^2$.\\
$\text{Var}(aX+b) = a^2 \text{Var}(X)$.\\
standard deviation, $\text{SD}(X) = \sqrt{\text{Var}(X)}$.\\
Bernoulli random variable, special case $(1,p)$ of binomial random variable $(n,p)$. $X$ represents the number of successes occur in the $n$ trials, $p(i)={n\choose i} p^i (1-p)^{n-i}$.\\
properties of Bonomial Random Variables, $E[X^k] = np E[(Y+1)^{k-1}]$, thus $E[X]=np$, $E[X^2] = np[(n-1)p+1]$, $\text{Var}(X) = np(1-p)$.\\
prop, binomial, increasing monotonically then decreasing monotonically, reaching its largest value when $k=\lfloor (n+1)p \rfloor$.\\
Poisson random variable, $p(i) = e^{-\lambda} \frac{\lambda^i}{i!}, i=0,1,2,...$; approximation for Binomial $(n,p)$ when $n$ is large, $p$ is small enough, let $\lambda=np$. $E[X]=\lambda$, $\text{Var}(X)=\lambda$.\\
Based on 3 assumptions: probability exactly 1 event occurs in a given interval length $h$ is, $\lambda h+o(h)$, i.e. $\lim_{h\rightarrow 0}o(h)/h = 0$; probability that 2 or more events occur in an interval os length $h$ is, $o(h)$; For any interger $n$, nonoverlapping interval $j_1,...,j_n$, event occur $E_i$ be occur in $j_i$, which are independent. Then number of occur in interval of length $t$ is Poisson random variable with mean $\lambda t$.\\
%total r successes, require trials n.
geometric random variable, special case $(1,p)$ of negative binomial random variable $(r,p)$. $P\{X=n\} = {n-1\choose r-1} p^r(1-p)^{n-r}, n=r,r+1,...$; $E[X^k] = \frac{r}{p}E[(Y-1)^{k-1}]$, $E[X]=r/p$, $E[X^2]=\frac{r}{p}(\frac{r+1}{p}+1)$, $\text{Var}(X)=\frac{r(1-p)}{p^2}$.\\
%N+1 succ, 2N-k+1 trials, nega bino.
The Banach match problem\\
hypergeometric random variable,
\begin{align}
	&P\{X=i\} = \frac{{m\choose i}{N-m\choose n-i}}{{N\choose n}}, i=0,1,...,n\\
	&E[X^k] = \frac{nm}{N} E[(Y+1)^{k-1}]\\
	&E[X] = \frac{nm}{N}\\
	&E[X^2] = \frac{nm}{N}\left[\frac{(n-1)(m-1)}{N-1}+1\right]\\
	&\text{Var}(X) = np(1-p)(1 - \frac{n-1}{N-1}),\ \text{let $p=m/N$}
\end{align}
when $N$ is large compare to $n$, approximation for binomial.\\
zeta distribution, $P\{X=k\} = \frac{C}{k^{\alpha +1}}, k=1,2,...$.\\
prop, $E[X]=\sum_{s\in S} X(s)p(s)$.\\
corollary, $E[\sum X_i] = \sum E[X_i]$.\\

\section{Continuous Random Variables}
probability density function.\\
prop, with real-valued $g$, that $E[g(X)] = \int_{-\infty}^\infty g(x)f(x)dx$.\\
%for dy, scaned length y.
lemma, nonnegative $Y$, $E[Y]=\int_0^\infty P\{Y>y\}dy$.\\
Corollary, $E[aX+b] =aE[X]+b$, $\text{Var}(aX+b)=a^2\text{Var}(X)$.\\
uniformly distributed, $\text{Var}(X)=(b-a)^2/12$.\\
Bertrand's paradox, should define what kind of random.\\
normal distribution. $(\mu,\sigma^2)$. standard $Z =(X-\mu)/\sigma$\\
The DeMoivre-Laplace limit theorem, let  $S_n$ denotes the number of successes occur when $n$ independent trials, each probability $p$, i.e. binomial $(n,p)$. Then for any $a<b$, as $n\rightarrow \infty$:
\begin{align}
	P\left\{a\leq \frac{S_n-np}{\sqrt{np(1-p)}}\leq b\right\}\rightarrow \Phi(b) - \Phi(a)
\end{align}
Which is special case of central limit theorem. Recall $n$ is large, $p$ is small enough, approx Poisson.\\
%e.g. Half-life
exponential random variable. a key property memoryless. $P\{X>s+t|X>t\} = P\{X>s\}$.\\
Hazard Rate Functions\\
gamma distribution, $(\alpha,\lambda)$, $\lambda>0$.\\
The Weibull Distribution\\
The Cauchy Distribution\\
The Beta Distribution, note $B(a,b)=\Gamma(a)\Gamma(b)/\Gamma(a+b)$.\\
Thm, suppose $g(x)$ strictly monotonic(imply bijective), differentiable, the pdf of $Y=g(x)$ given by
\begin{align}
	f_Y(y)=\begin{cases} f_X[g^{-1}(y)]\left|\frac{d}{dy}g^{-1}(y)\right| & \mbox{if $y=g(x)$}\\
				0 & \mbox{if $y\neq g(x)$}\end{cases}
\end{align}





\end{document}